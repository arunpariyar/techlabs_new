{"data":{"allContentfulBlogPost":{"edges":[{"node":{"title":"Raum- und Geodatenanalyse Münster","timeToRead":"6 min read","content":{"childContentfulRichText":{"html":"<p>Das Projekt trägt den Namen Raum- und Geodatenanalyse Münster. Die Projektidee hatte im Laufe der Projektphase zwei Gesamtüberarbeitungen, was recht spannend war mitzuerleben.</p><p>Da der ursprüngliche Projektinitiator nicht unserer Gruppe zugeordnet wurde, waren wir am Projekt-Kick Off zu aller erst ahnungslos. Wir verstanden aus der Projektbeschreibung nicht, welches das Ziel war. Am Ende der ersten Überarbeitung konnten wir den Ideengeber per Zufall ausfindig machen und er erklärte uns:</p><p>Aus Geodaten, die wir aus dem Internet beziehen, sollte eine Analyse über die Stadt Münster erfolgen, bei der Stadtteile bzw. bestimmte Orte vorhergesagt werden, die bei der Gefahr von Hochwasser besonders betroffen wären.</p><p>Wir waren zu zweit (die anderen Mitglieder waren verhindert) und wir kannten also nur die Wörter: Raumdatenanalyse, Stadt und Münster. Das lässt ziemlich viel Spielraum übrig. Daraufhin haben wir gebrainstormt und sind auf eine andere interessante Idee gekommen:</p><p>Fahrraddaten in Münster auszuwerten mit der Fragestellung, wie sich Fahrradverkehrsströme verhalten. Da wir schon in Münster leben, darf die Leeze auch nicht fehlen!</p><p>Dieses sollte in Abhängig vom Zeitpunkt, den Wetterbedingungen und den Verkehrsströme der Autofahrer, etc. untersucht werden. Wo und wann kommt es vermehrt zu Fahrradunfällen, um dann zu untersuchen von welchen Variablen (Zeit, Ort, Verkehr) dieses abhängig ist.</p><p>Im Zeitraum von zwei Wochen wurde die Idee ein wenig weitergesponnen und als letztes und endgültiges Ergebnis entstand ein Erlebnisroutenplaner mit dem Stichwort:Kneipentour.</p><p>Ein Routenplaner schlägt eine Route mit drei offenen Kneipen, die alle offen haben.</p><p>Zwischen Hochwasser und Kneipentour-Empfehler ist ordentlich viel Raum, was jedoch das Aufregende war. Die Projektidee war nicht in Stein gemeißelt und das eigentliche Projekt konnte interaktiv und iterativ gestaltet werden.</p><p>Das konkrete Projekt sollte sich mit der Erstellung eine App befassen, welche mittels eines Recommenders dem Nutzer eine Kneipentour vorgeschlagen wird. Es soll eine zufällige Auswahl von <b>n</b> Kneipen, den Kriterien entsprechend, getroffen werden. Die Rahmenbedingungen, wie Entfernung und Zeitfenster, sollen berücksichtigt werden. Mittels eines Routing-Algorithmus sollte eine dem Verkehrsmittel entsprechend optimierte Route vorgeschlagen werden. Die Kriterien sollen Eigenschaften, wie Gemütlichkeit, Coolnessfaktor und Preise beinhalten. Es muss jedoch ein Datensatz mit den Kneipen, Bars und Gaststätten mit Öffnungszeiten, Ort und Informationen generiert werden.</p><p>Der Start für den User beginnt bei dem UI, in dem er seine Angaben über den geplanten Abend macht. Am Ende des Abends bewertet der Nutzer die Tour und die Lokalitäten.</p><p>Wir kannten das Ziel, und die Meilensteine waren: die Erstellung eines Datensatzes mit genügend Informationen, das Routing-Problem, die Erstellung eines User-Interfaces, das Coden eines vernünftigen Recommenders.</p><p>Unsere Ressourcen waren ein Team aus 5 Techies mit allen drei Tracks-Ausrichtungen: Drei Data-Science-Python-Anhänger, ein AI’ler und ein WebDev-Techie. Ergo waren wir breit aufgestellt.</p><p>Jeder Meilenstein geht mit unterschiedlichen Schwierigkeiten einher.</p><p>Die Generierung eines Datensatzes erfolgte mittels Web Scraping. Es muss zuerst eine vernünftige Quelle, die viele relevante und notwendige Informationen beinhaltet, gefunden werden. Es wurden passendere und weniger geeignete Seiten, wie Yelp, Facebook, usw. gefunden. Es wurde sich auf eine heimische und münsteraner Seite <a href=\"http://www.muenster-geht-aus.de/\">www.muenster-geht-aus.de</a> festgelegt.</p><p>Hier haben sich die Data Scientists ran getraut und die Seiten auf die Lokalitäten ausgelesen. Es ist interessant zu erfahren, was hinter WebScrapping alles steckt und dabei gelernt wird. Die Internetseite muss zuerst auf seine Struktur „erforscht“ werden. Dann muss eine Strategie entwickelt werden, wie die gewünschten Seiten erreicht werden, um diese dann auf ihren Inhalt auszulesen.</p><p>Um diese Herausforderung zu bewältigen, diente BeautifulSoup, welches aus dem Roh-HTML-Text (der sogenannten Soup) einen geordneten und lesbaren Text („die schöne Suppe“) macht. Der Text wird daraufhin selektiert, sodass nur die gewünschten Informationen gesammelt werden. Dieses wird dann in ein DataFrame verpackt. Siehe da, es konnten 300 Internetseiten innerhalb von 3,5 Minuten auf ihren Inhalt gezielt „gescrawlt“ werden.</p><p>Das Paket Geopy diente dazu das gesamte Routing-Problem zu lösen. Es musste eine Infrastruktur erhalten werden, um die Positionen der Lokalitäten aus den Adressen zu bestimmen. Geopy half dabei die Adresse aus dem Datensatz mit Ortskoordinaten zu koppeln. Dieselbe Bibliothek kann ebenfalls die Distanz per Luftlinie bestimmen.</p><p>Die Erstellung eines User-Interfaces hat sich letzten Endes als schwierig herausgestellt, da unser WebDev-Spezialist sich aus dem Projekt entzogen hat. Aber das ist kein Problem für Sven, den Data-Science Pythonisten. Er konnte eine pragmatische Lösung für eine UI coden. Seine Notfalllösung bestand aus einer PyQT-Anwendung, die ein User-Interface erstellt.</p><p>Das Coden eines vernünftigen Recommenders ist derzeit recht spannend. Als erstes musste in Erfahrung gebracht werden, was überhaupt ein „recommendation engine“ ist. Ein Empfehlungssystem ist ein simpler Algorithmus, welcher das Ziel hat, den Nutzer mit der am meisten relevanten Information zu versorgen. Die Informationen werden durch Erforschung von Mustern aus dem Datensatz bezogen. Ein Beispiel dafür ist die Empfehlungs-Maschine von Netflix. Diese schlägt den Nutzer Filme und Serien vor, die ihm gefallen könnten. Es gibt zahlreiche Anwendungen in bekannten Plattformen, wie Amazon, Apple Music, usw.</p><p>Es gibt eine große Anzahl an Typen von „recommendation engines“. Die üblichen Arten sind sogenannte „collaborative filtering“ und „content-based“ Empfehlungssysteme.</p><p>Beim collaborative filtering wird das Verhalten einer Nutzergruppe verwendet, um Empfehlungen für andere Nutzer zu treffen.</p><p>Bei content-based Systemen hingegen werden Meta-Daten verwendet, um Gegenstände weiter zu empfehlen. Diese Daten sind zum Beispiel Genre, Schauspieler, Nationalität des Filmes.</p><p>Wir standen vor der Fragestellung, ob unsere Daten dafür geeignet sind, da wir keine Meta-Daten für ein content-based System und weder Bewertungen noch Nutzer-Historien zur Verfügung hatten.</p><p>Wir hatten nur eine kurze Beschreibung der Lokalitäten, sodass wir uns für ein regel-basiertes Modell entschieden haben. Wir mussten also den Text auf seine Wörter analysieren und die Wortfrequenzen bestimmen. Manche Begriffe müssen häufiger als andere vorkommen. Jedoch war die Verteilung nicht erwartet wie gewünscht. Die meisten Wörter wurden nicht richtig gezählt, da z.B. „legendär“ und „legendäre“ nicht zusammen gefasst werden.</p><p>Wir mussten also Text-Mining-Grundlagen verwenden. Das nltk (Natural Language Toolkit) Paket war unsere Rettung. Der Text muss zuerst vorverarbeitet und dann vereinheitlicht werden. Der Text wird also „tokenisiert“: Der Text wird in einzelne Wörter (Tokens) zerlegt. Im nächsten Schritt müssen die Tokens normalisiert werden, indem unterschiedliche flektierte Wortformen als gleiches Wort registriert werden. Das sogenannte „Stemming“ bildet unterschiedliche Wortformen auf den selben Wortrumpf oder Wortstamm ab. Der German-Stemmer aus dem nltk Paket erledigt genau dies für uns. Dieser entfernt Wortendungen, Umlaute, etc., sodass wir manuell nur Stoppwörter entfernen und kleine Anpassungen durchführen müssen. Es konnten also nun Wörter gezählt werden! Die Verteilung der Wörter war informativer, sodass wir diese clustern konnten. Um es nicht zu verkomplizieren, wurden die am häufigsten vorkommenden Wörter per Hand ausgewertet. Die Wörter konnten den Stimmungen oder dem Muster „entspannt, modern, romantisch, party, klassisch und legendär“ zugeordnet werden. Derzeitig befinden wir uns noch dabei den regel-basierten Algorithmus fertigzustellen, damit ihr eure Kneipentour nach diesen Mustern bestimmen könnt!</p><p>Wir hatten also einen Datensatz erstellt, welcher Geolocations enthält und somit die Route erstellt werden kann. Es ist eine vorübergehende UI erstellt worden und die Clubs &amp; Kneipen konnten Clustern zugeordnet werden. Das Empfehlungssystem ist derzeitig noch in Entstehung.</p><p>Was waren die größten Herausforderungen?</p><p>Ich glaube es gibt fachlich keine nicht-lösbaren Probleme in den Projekten. Die Projekte wurden mit unserem Mentor überarbeitet, der auch ständig bei Schwierigkeiten hilft. Es ist eher eine Herausforderung eine simple und passende Lösung zu finden. Simple heißt nicht, die erste als auch nicht die komplizierteste, sondern eine passende Lösung, selbst wenn man Zeit in andere Möglichkeiten investiert hatte. Ach und außerdem, Google ist dein bester Freund!</p><p>Die Unsicherheit die Herausforderung nicht zu bewältigen, demotiviert einen zwischendurch. Wichtig war es einfach weiterzumachen und mich mit anderen Techies auszutauschen, sodass man sich gegenseitig hilft und motiviert. Der Community-Faktor ist bei TechLabs das Besondere. Es gab coole Vorträge und Hackathons, bei denen man gemeinsam gecoded hat. Man ist also nicht auf sich allein gestellt.</p><p>Eine Herausforderung war es teils einen Spagat zwischen der Universität, Freizeit und TechLabs zu machen. Es ist manchmal anzustrengend gewesen, aber man konnte sich die Arbeit aufteilen.</p><p>Der Anfang der Projektphase war zwar holprig, aber wir konnten unser Projekt nach unseren Vorstellungen gestalten. Wir wurden zwar recht schnell nur zu einer Zweier-Gruppe, doch unser Mentor hat uns die ganze Zeit unterstützt.</p><p>Wenn man ein Anfänger ohne Vorkenntnisse ist betritt man eine noch komplett unbekannte Welt, die einen öfters verunsichert. Hier liegt eine der größten Herausforderungen im Persönlichen. Die Hemmschwelle Probleme zuzugeben ist ziemlich groß, sodass diese eventuell nicht mitgeteilt werden. Ich muss sagen, ich hatte keine Vorkenntnisse und nun habe ich ein neues Hobby gefunden! Mein Horizont wurde durch TechLabs erweitert, sodass ich meine Spezialisierung meines Masterstudiums in Richtung Digitalisierung der Chemie-Industrie sehe.</p><p>Mein größter Erfolgsmoment war nach dem 200sten automatisierten Auslesen der Website. Es hatte endlich geklappt. Man lernt soviel dazu und es gibt keine bessere Abwechslung zum Hörsaal. — Jesús Andrés Duarte Traebecke</p>"}},"authorName":null}},{"node":{"title":"Smart City: Visualizing bike traffic in Münster","timeToRead":"11 min read","content":{"childContentfulRichText":{"html":"<p>Urban mobility and increasing traffic are major problems in German cities. This encompasses various forms of traffic like buses, trains, traffic light management and provision of additional parking spaces to name a few. Tracking traffic, predicting future flows and thus providing sufficient resources at an early stage are crucial to tackle those issues. With almost everything involved in traffic creating data and technology as well as software capable of processing that data, data science is the way to create the solutions.</p><p>With urban mobility just being one example of application, data science and other digital skills play a central role in the everyday work today and more important in the future. Some might say “coding is the new literacy” (Anna Hülemeier). Making sure students are ready for the tech-driven future is the ambitious goal of TechLabs.</p><p>TechLabs is a Münster-based, non-profit organization that enables students regardless of their field of study to develop digital skills and expand their knowledge in coding and tech trends. Participants can choose from three different learning tracks: Web Development, Data Science and Artificial Intelligence. A track consists of different online learning materials put together by experienced students in the respective fields. At the end of a TechLabs semester, the acquired skills and knowledge can be applied in a group project. This blog post is the outcome of such a project, tackling aspects of urban mobility.</p><h4>Our Team</h4><p>Our project team consists of five students. Three of us are specialized in Data Science via TechLabs and are studying economics in Münster. The other two expanded their knowledge in Artificial Intelligence and Information Systems students in Münster. This gives us diverse IT skills as some of us have already acquired programming or data science skills during their studies while others brought fresh ideas into the new field.</p><h4>Traffic in Münster</h4><p>In the future, trending concepts like e-mobility and car sharing are gaining significance on urban mobility. Currently, though, a growing number of cars, travelers and increasingly congested roads account for the majority of problems in urban mobility. As TechLabs was founded in Münster and our project team consists of students from Münster, our project will be initially focused on Münster.</p><p>In comparison to the top jammed cities in Germany Münster is doing okay. Nevertheless, you get frustrated when you are among the 360,000 commuters that squeeze through the streets of Münster every day (<a href=\"https://www.stadt-muenster.de/verkehrsplanung/verkehr-in-zahlen.html\">https://www.stadt-muenster.de/verkehrsplanung/verkehr-in-zahlen.html</a>). At peak times, there is no getting through at hotspots like the Ludgerikreisel or other main roads. Public transport is not really an option either because buses use the same roads as the commuters.</p><p>For people living in Münster, there is really just one option to get fast from A to B. And that is going by bike. Numbers proof that: 400,000 routes are covered by bike per day (<a href=\"https://www.stadt-muenster.de/verkehrsplanung/verkehr-in-zahlen.html\">https://www.stadtmuenster.de/verkehrsplanung/verkehr-in-zahlen.html</a>). In 2016, 4,105,177 bicycles were recorded at the counting point at the central location Neutor in Münster, which corresponds to an average of 467 bicycles per hour. On Wolbecker Straße, fewer but still 3,589,382 bicycles were recorded in 2016. Münster has earned his name as bike capital of Germany. Bikes are especially popular among students. They are cheap, do not take up much space and you get to everywhere you want in Münster. Bikes are so popular in fact, that they cause traffic jams on bikeways. Approximately 60,500 students are living in Münster which corresponds to around 19 % of the overall population. University buildings and student residences being spread all over Münster, a huge traffic flow of students exists every day.</p><h4>Our goal</h4><p>With the bike being the most convenient (and also eco-friendly) alternative to car and bus, it must be assured that using it will remain convenient in the future. You have to get to your destination fast and safe. And with already so many bikes in use and no decrease in sight, that will remain a challenge.</p><p>The goal of our project is the identification of bottlenecks in the bike infrastructure in Münster. Therefore, we dealt with the following questions:</p><ul><li><p>How are students and university buildings in Münster distributed?</p></li><li><p>Where are the main traffic flows between student residences and university buildings?</p></li><li><p>What are the bottlenecks in the bike infrastructure in Münster?</p></li></ul><h4>Inspiration</h4><p>In our first meeting, we drew inspiration from a resource our mentor provided us with. It was Mark Padgham’s project in the field of planning the future of transport which he presented to the Münster UseR Meeting on November 20, 2018 (<a href=\"https://github.com/mpadge/ms-user-meetup-nov2018\">https://github.com/mpadge/ms-user-meetup-nov2018</a>). He analyzes randomly distributed points and their traffic connection via bicycle and car. That project became the basis for our project.</p><p>As there are differences in the possibilities provided by R and Python, we were hoping to incorporate the specific advantages Python has over R like being able to handle larger datasets as well as the potential to be used beyond basic research analysis.</p><h4>Project work</h4><p>Our mentor helped us to find a starting point into the project by giving us advice and useful resources. However, the necessary steps were not obvious to us from the beginning, since neither of us has been involved in a project like this before. Through research and collaboration, we got to our goal step by step.</p><h4>Getting ready</h4><p>After setting our goal and getting familiar with the UseR Meeting presentation, we gathered ideas to realize the project. To get a first overview, we determined the main university locations on a Google Map. We then tried to identify where most students are living. Since they are literally everywhere in Münster, we decided to just predefine uni locations and set the starting points of the routes to those places randomly.</p><h4>Open Street Maps</h4><p>During the development phase, we heavily relied on Open Street Maps (OSM). It is the main platform we used to visualize Münster’s road network as it is “(…) the most comprehensive street atlas humanity has ever created” (<a href=\"https://mpadge.github.io/ms-user-meetup-nov2018/slides/ms-meetup-nov18.html#21\">Mark Padgham</a>).</p><p>It represents roads and buildings using<a href=\"https://wiki.openstreetmap.org/wiki/Tags\"> tags</a> attached to its basic data structures (its<a href=\"https://wiki.openstreetmap.org/wiki/Nodes\"> nodes</a>,<a href=\"https://wiki.openstreetmap.org/wiki/Ways\"> ways</a>, and<a href=\"https://wiki.openstreetmap.org/wiki/Relations\"> relations</a>). The tags itself contain a geographic attribute of the subject being shown by that specific node, way or relation.</p><p>Users can create their individual keys and locations that are relevant to their projects allowing OSM to be very versatile concerning the means of use. Most features can be described using only a small number of tags, such as a path with a classification tag such as<a href=\"https://wiki.openstreetmap.org/wiki/Key:highway\"> “highway</a>=<a href=\"https://wiki.openstreetmap.org/wiki/Tag:highway%3Dfootway\">footway</a>”.</p><p>As there are constant updates regarding roads and buildings all over the world, OSM is a very precise and reliable source for the analysis as well as the visualization of projects like “Smart City”. Furthermore, OSM uses the standard ESPG 4326 which is commonly used in cartography. The main servers reside in the University College London (UCL) as well as the Imperial College London (ICL) allowing OSM to be classified as stable and effective.</p><p>In order to incorporate Python, the OSMnx package needed to be included as the “Python for street networks (…) [used to] retrieve, model, analyze, and visualize street networks and other spatial data from OpenStreetMap” (<a href=\"https://github.com/gboeing/osmnx\">gboeing/osmnx</a>). This package was used via the Jupyter Notebook option provided by Anaconda. OSMnx is to be used in combination with geopandas, networkx, and matplotlib in order to construct and analyze street networks. The OSMnx package proved to be rather difficult to install on certain laptops which slowed down the coding process for some of our team members but also resulting in an improved knowledge of the package via intense research on how to install this package as well as the causes for the previously mentioned failure.</p><h4>Step by step to the solution</h4><p>We started off the coding phase of the project rather simple with the task of visualizing Münster as a street network. We played around a bit to get familiar with OSM. Because drawing a graph of a whole city takes rather long, we sticked to the “Altstadt” over the next steps.</p><p>Next up, we wanted to integrate routes to our project. We took two random nodes of the graph and let Python compute the shortest path between those nodes. We got more specific by defining our own places. Those places not necessarily correlated to nodes of the graph. We had to find the closest nodes to the respective places in order to compute a route. Being able to compute a route between predefined places was the first big achievement of our project.</p><p>The next step was to create and display multiple routes in one graph. For the start, we let the routes be created manually. To be able to identify highly frequented streets, we turned down the opacity of the routes to 0.1 (route_alpha=0.1).</p><p>It became apparent rather soon that coding each flow individually was the easiest but also the most time consuming way. It was helpful for testing but for our application to be useful we have to create hundreds, or thousands of routes, and hence that has to be done automatically. In order to provide a more efficient solution, a for loop was created. In every iteration on route is created and saved to a list. After all routes have been created, that list was used as an argument in the visualization function of OSMnx.</p><p>Being able to efficiently create multiple routes, we then integrated the university locations we determined in the beginning. Therefore, we split up the work, so some of our team translated the places from the Google Map to usable data in Python via the ox.geocode() option while the others continue coding. Those places being the endpoints of our routes, we set the “Dom” in the center of Münster as starting point for testing purposes. Uni buildings being spread all over Münster, we also had to expand the area of the graph to the whole city.</p><p>That graph was showing us that we are on the right way to achieve our goal. The only thing missing were realistic starting points for the routes. As said in the beginning, we decided to not predefine those points but want to use random places.</p><p>We therefore changed the for loop to take a random point in the graph as starting point and pick one of the university locations randomly as end points. To get a meaningful visualization we played around with the number of routes being created. The for loop gets the number of random points as argument. This number represents the total number of routes which will be created. We ended up with 2000 routes. The resulting graph is the final result of this project.</p><p>The individual flows are shown in a rather transparent orange leading to certain streets being richer and darker in colour if several flows prefered the usage of this specific street creating a kind of layering-effect. We opted out of creating a heatmap which would require a specific explanation of the different colours and chose a more user-friendly and self-explaining solution.</p><p>At the end of our project we used another package for visualizing the routes. This package is called Folium. In contrast to the previous solution, Folium is an interactive graphic. The biggest problem is that this map can display only a few routes because of its performance.</p><p>The final python script can also be applied to other cities with a few changes. Additionally, we can visualize car traffic as well.</p><p>The TechLabs Curriculum was based on independent learning and the “hands-on” approach of e.g. the Data Camp courses. Because of this, each of our team members was already used to the general concept of coding in Python and using “trial and error” to determine whether their approach to a certain problem was effective or not. This being said, our problem solving techniques relied heavily on Google searches and the support of our mentors who were always very keen on helping us out while still giving us the freedom to make our own mistakes and learn from them.</p><p>The main reason for the Google searches was the specialized package OSMnx. The online courses help us to generate automatically routes.</p><h4>Difficulties</h4><p>Using the OSMnx package brought some problems with it. It created an at first unsolvable error that was dealt with in one of our meetings as the specific document in our github folders had to be properly traced back for each one of our team members in order for Jupyter Notebook to find and utilize the correct document. As soon as the proper document was traced back and the “os” package was imported, the code could finally be run properly without producing a “RunTime Error”.</p><p>In retrospective, setting up the environment and downloading and installing all the required packages was the most complicated part. That was annoying when we wanted to get going and get stuff done but some installation error or incompatibility kept us from doing so.</p><h4>Conclusion</h4><p>Initially our goals were to visualize the distribution of student residences and university buildings, create flows between them and hence identify the main traffic flows, so called bottlenecks in the bike infrastructure.</p><p>In the end we were able to achieve all these checkpoints: we’ve created a map of the city centre of Münster, displayed the university buildings and coded random student residences as well as flows between those points.</p><p>Our analysis confirmed bottlenecks in the bike infrastructure at places like the “Ludgerikreisel” and “Aegidiimarkt” — much as we expected. Interestingly, the “Promenade” — a street only allowed to be used by bike, is used very little according to our visualization — but empirically it is quite crowded as well.</p><p>What happened here — is there a mistake in our analysis? No, since the flows were meant to find the shortest routes. The “Promenade” is most of the time a circuitous way, but still bikers like to use it, because of its beauty and quietness. Thus, the possibility to weight certain routes more heavily would be one way to refine our visualisation and make it even more realistic. Furthermore, this project could be extended to identify bottlenecks in public transport.</p><p>Overall TechLabs provided a unique opportunity to strengthen or establish coding and tech skills. Regardless of whether it was ones first contact with coding, or participants already had a decent understanding — with the right amount of ambition everyone was able to make a big step in there Tech-career.</p><p>The idea to put the project teams together because of the general interest in the theme and not based on individual tech knowledge showed once more, that initiative and willingness actually decide whether the team succeeds or fails.</p><p>TechLabs is not only a great possibility to find a guided entrance into the coding world or efficiently improve ones skills with a hands on learning approach, but also an exceptional chance to experience the strength and drive resulting from a fully committed team.</p><p>Team:</p><p>Christoph Hoppe</p><p>Christopher Eßmann</p><p>Marie Landwehr</p><p>Ronja Köhling</p><p>Simon Röckinghausen (https://www.linkedin.com/simon-roeckinghausen/)</p><p>Betreuer: David Middelberg</p>"}},"authorName":"Inside TechLabs"}}]}},"pageContext":{"isCreatedByStatefulCreatePages":true}}